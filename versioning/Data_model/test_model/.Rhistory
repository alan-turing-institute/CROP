mean_tail_diff <- function(vector) {
diff <- mean(vector,na.rm=TRUE) - tail(vector,n=1)
return (diff)
}
data_folder = "datasets/data"
results_folder = "results"
library(purrr)
library(cleanEHR)
# full dataset
load(paste(data_folder,"anon_public_d.RData",sep="/"))
# use a smaller sample
#load(paste(data_folder,"sample_ccd",sep="/"))
# Extract all non-longitudinal data (demographic, time, survival status, diagnosis)
#dt <- ccd_demographic_table(ccd, dtype=TRUE)
dt <- ccd_demographic_table(anon_ccd, dtype=TRUE)
# play a bit with the data
# explore spells
#head(ccd_unique_spell(anon_ccd, duration=2)[, c("episode_id", "spell")])
# how to get short variable names
#code2stname("NIHR_HIC_ICU_0553")[[1]]
# plot some longitudinal data
pdf(paste(results_folder,"example_episode.pdf",sep="/"))
plot_episode(anon_ccd@episodes[[7]], c("h_rate",  "bilirubin", "fluid_balance_d", "temperature_central"))
dev.off()
# sex
pdf(paste(results_folder,"hist_sex.pdf",sep="/"))
barplot(prop.table(table(dt$SEX)))
dev.off()
# weight
pdf(paste(results_folder,"hist_weight.pdf",sep="/"))
hist(dt$WKG)
dev.off()
# height
pdf(paste(results_folder,"hist_height.pdf",sep="/"))
hist(dt$HCM)
dev.off()
# exporting the data to a python friendly format
# we want a tabular dataset with the time series reduced to a set of point statistics for simplicity (this could/should be improved upon eventually)
# Write demographics dt to CSV
write.table(dt, file = paste(data_folder,"anon_public_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# get the codes of time series variables
names_ts_variables <- c()
counter <- 1
for (i in 1:length(anon_ccd@episodes)){
for (n in names(anon_ccd@episodes[[i]]@data)){
if (length(anon_ccd@episodes[[i]]@data[n][[1]]) == 2){ # guarantee time series
names_ts_variables[[counter]] <- n
counter <- counter+1
}
}
}
names_ts_variables <- sort(unique(names_ts_variables))
short_names_ts_variables <- lapply(names_ts_variables, FUN = code2stname)
# our index is NIHR_HIC_ICU_0005, corresponding to a unique (per episode/patient) admission number, or ADNO
index_variable <- "NIHR_HIC_ICU_0005"
# prepare lists of measurements from time series
ts_measures <- c("mean","std","last","mean_tail_diff")
#ts_measures <- c("mean","1st_quartile","median","3rd_quartile","std","max","min")
#ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(quantile,probs=c(0.25),na.rm=TRUE),partial(quantile,probs=c(0.5),na.rm=TRUE),partial(quantile,probs=c(0.75),na.rm=TRUE),partial(sd),partial(max, na.rm = TRUE),partial(min, na.rm = TRUE))
ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(sd),partial(tail,n=1),partial(mean_tail_diff))
names_for_dts <- c("ADNO")
for (sn in short_names_ts_variables){
for (mes in ts_measures){
names_for_dts <- append(names_for_dts,paste(sn,mes,sep = "_"))
}
}
dts <- data.frame(matrix(NA, nrow=0, ncol=length(names_for_dts)))
names(dts) <- names_for_dts
## prepare TS dataset
for (i in 1:length(anon_ccd@episodes)){
adno <- as.numeric(anon_ccd@episodes[[i]]@data[index_variable][[1]])
measurements <- c(adno)
for (n in names_ts_variables){
# Add time limit of 48 hours to measure TS data!
dt_ <- anon_ccd@episodes[[i]]@data[n][[1]]
time_ = dt_$time <10
dt_ <- dt_[time_,]
values <- dt_[time_,]["item2d"][[1]]
if (!is.null(dt_) && !is_empty(values)){
for (measure in ts_measures_funcs){
measurements <- c(measurements,measure(as.numeric(values))[[1]])
}
} else {
measurements <- c(measurements,rep(NA,length(ts_measures)))
}
}
dts <- rbind(dts,measurements)
names(dts) <- names_for_dts
}
# Write TS dt to CSV
write.table(dts, file = paste(data_folder,"anon_public_timeseries.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# CleanEHR AIDA use case
# This script takes the available data and exports it for further analysis in Python
# Giovanni Colavizza <gcolavizza@turing.ac.uk> and Camila Rangel Smith <crangelsmith@turing.ac.uk>
# November 2018
# point this to the CleanEHR data
mean_tail_diff <- function(vector) {
diff <- mean(vector,na.rm=TRUE) - tail(vector,n=1)
return (diff)
}
data_folder = "datasets/data"
results_folder = "results"
library(purrr)
library(cleanEHR)
# full dataset
load(paste(data_folder,"anon_public_d.RData",sep="/"))
# use a smaller sample
#load(paste(data_folder,"sample_ccd",sep="/"))
# Extract all non-longitudinal data (demographic, time, survival status, diagnosis)
#dt <- ccd_demographic_table(ccd, dtype=TRUE)
dt <- ccd_demographic_table(anon_ccd, dtype=TRUE)
# play a bit with the data
# explore spells
#head(ccd_unique_spell(anon_ccd, duration=2)[, c("episode_id", "spell")])
# how to get short variable names
#code2stname("NIHR_HIC_ICU_0553")[[1]]
# plot some longitudinal data
pdf(paste(results_folder,"example_episode.pdf",sep="/"))
plot_episode(anon_ccd@episodes[[7]], c("h_rate",  "bilirubin", "fluid_balance_d", "temperature_central"))
dev.off()
# sex
pdf(paste(results_folder,"hist_sex.pdf",sep="/"))
barplot(prop.table(table(dt$SEX)))
dev.off()
# weight
pdf(paste(results_folder,"hist_weight.pdf",sep="/"))
hist(dt$WKG)
dev.off()
# height
pdf(paste(results_folder,"hist_height.pdf",sep="/"))
hist(dt$HCM)
dev.off()
# exporting the data to a python friendly format
# we want a tabular dataset with the time series reduced to a set of point statistics for simplicity (this could/should be improved upon eventually)
# Write demographics dt to CSV
write.table(dt, file = paste(data_folder,"anon_public_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# get the codes of time series variables
names_ts_variables <- c()
counter <- 1
for (i in 1:length(anon_ccd@episodes)){
for (n in names(anon_ccd@episodes[[i]]@data)){
if (length(anon_ccd@episodes[[i]]@data[n][[1]]) == 2){ # guarantee time series
names_ts_variables[[counter]] <- n
counter <- counter+1
}
}
}
names_ts_variables <- sort(unique(names_ts_variables))
short_names_ts_variables <- lapply(names_ts_variables, FUN = code2stname)
# our index is NIHR_HIC_ICU_0005, corresponding to a unique (per episode/patient) admission number, or ADNO
index_variable <- "NIHR_HIC_ICU_0005"
# prepare lists of measurements from time series
ts_measures <- c("mean","std","last","mean_tail_diff")
#ts_measures <- c("mean","1st_quartile","median","3rd_quartile","std","max","min")
#ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(quantile,probs=c(0.25),na.rm=TRUE),partial(quantile,probs=c(0.5),na.rm=TRUE),partial(quantile,probs=c(0.75),na.rm=TRUE),partial(sd),partial(max, na.rm = TRUE),partial(min, na.rm = TRUE))
ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(sd),partial(tail,n=1),partial(mean_tail_diff))
names_for_dts <- c("ADNO")
for (sn in short_names_ts_variables){
for (mes in ts_measures){
names_for_dts <- append(names_for_dts,paste(sn,mes,sep = "_"))
}
}
dts <- data.frame(matrix(NA, nrow=0, ncol=length(names_for_dts)))
names(dts) <- names_for_dts
## prepare TS dataset
for (i in 1:length(anon_ccd@episodes)){
adno <- as.numeric(anon_ccd@episodes[[i]]@data[index_variable][[1]])
measurements <- c(adno)
for (n in names_ts_variables){
# Add time limit of 48 hours to measure TS data!
dt_ <- anon_ccd@episodes[[i]]@data[n][[1]]
time_ = dt_$time <10
dt_ <- dt_[time_,]
values <- dt_[time_,]["item2d"][[1]]
if (!is.null(dt_) && !is_empty(values)){
for (measure in ts_measures_funcs){
measurements <- c(measurements,measure(as.numeric(values))[[1]])
}
} else {
measurements <- c(measurements,rep(NA,length(ts_measures)))
}
}
dts <- rbind(dts,measurements)
names(dts) <- names_for_dts
}
# Write TS dt to CSV
write.table(dts, file = paste("/Users/myong/Documents/anon_publicd_timeseries.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
write.table(dt, file = paste("/Users/myong/Documents/anon_publicd_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# CleanEHR AIDA use case
# This script takes the available data and exports it for further analysis in Python
# Giovanni Colavizza <gcolavizza@turing.ac.uk> and Camila Rangel Smith <crangelsmith@turing.ac.uk>
# November 2018
# point this to the CleanEHR data
mean_tail_diff <- function(vector) {
diff <- mean(vector,na.rm=TRUE) - tail(vector,n=1)
return (diff)
}
data_folder = "datasets/data"
results_folder = "results"
library(purrr)
library(cleanEHR)
# full dataset
load(paste(data_folder,"anon_public_d.RData",sep="/"))
# use a smaller sample
#load(paste(data_folder,"sample_ccd",sep="/"))
# Extract all non-longitudinal data (demographic, time, survival status, diagnosis)
#dt <- ccd_demographic_table(ccd, dtype=TRUE)
dt <- ccd_demographic_table(anon_ccd, dtype=TRUE)
# play a bit with the data
# explore spells
#head(ccd_unique_spell(anon_ccd, duration=2)[, c("episode_id", "spell")])
# how to get short variable names
#code2stname("NIHR_HIC_ICU_0553")[[1]]
# plot some longitudinal data
pdf(paste(results_folder,"example_episode.pdf",sep="/"))
plot_episode(anon_ccd@episodes[[7]], c("h_rate",  "bilirubin", "fluid_balance_d", "temperature_central"))
dev.off()
# sex
pdf(paste(results_folder,"hist_sex.pdf",sep="/"))
barplot(prop.table(table(dt$SEX)))
dev.off()
# weight
pdf(paste(results_folder,"hist_weight.pdf",sep="/"))
hist(dt$WKG)
dev.off()
# height
pdf(paste(results_folder,"hist_height.pdf",sep="/"))
hist(dt$HCM)
dev.off()
# exporting the data to a python friendly format
# we want a tabular dataset with the time series reduced to a set of point statistics for simplicity (this could/should be improved upon eventually)
# Write demographics dt to CSV
write.table(dt, file = paste(data_folder,"anon_public_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# get the codes of time series variables
names_ts_variables <- c()
counter <- 1
for (i in 1:length(anon_ccd@episodes)){
for (n in names(anon_ccd@episodes[[i]]@data)){
if (length(anon_ccd@episodes[[i]]@data[n][[1]]) == 2){ # guarantee time series
names_ts_variables[[counter]] <- n
counter <- counter+1
}
}
}
names_ts_variables <- sort(unique(names_ts_variables))
short_names_ts_variables <- lapply(names_ts_variables, FUN = code2stname)
# our index is NIHR_HIC_ICU_0005, corresponding to a unique (per episode/patient) admission number, or ADNO
index_variable <- "NIHR_HIC_ICU_0005"
# prepare lists of measurements from time series
ts_measures <- c("mean","std","last","mean_tail_diff")
#ts_measures <- c("mean","1st_quartile","median","3rd_quartile","std","max","min")
#ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(quantile,probs=c(0.25),na.rm=TRUE),partial(quantile,probs=c(0.5),na.rm=TRUE),partial(quantile,probs=c(0.75),na.rm=TRUE),partial(sd),partial(max, na.rm = TRUE),partial(min, na.rm = TRUE))
ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(sd),partial(tail,n=1),partial(mean_tail_diff))
names_for_dts <- c("ADNO")
for (sn in short_names_ts_variables){
for (mes in ts_measures){
names_for_dts <- append(names_for_dts,paste(sn,mes,sep = "_"))
}
}
dts <- data.frame(matrix(NA, nrow=0, ncol=length(names_for_dts)))
names(dts) <- names_for_dts
## prepare TS dataset
for (i in 1:length(anon_ccd@episodes)){
adno <- as.numeric(anon_ccd@episodes[[i]]@data[index_variable][[1]])
measurements <- c(adno)
for (n in names_ts_variables){
# Add time limit of 48 hours to measure TS data!
dt_ <- anon_ccd@episodes[[i]]@data[n][[1]]
time_ = dt_$time <10
dt_ <- dt_[time_,]
values <- dt_[time_,]["item2d"][[1]]
if (!is.null(dt_) && !is_empty(values)){
for (measure in ts_measures_funcs){
measurements <- c(measurements,measure(as.numeric(values))[[1]])
}
} else {
measurements <- c(measurements,rep(NA,length(ts_measures)))
}
}
dts <- rbind(dts,measurements)
names(dts) <- names_for_dts
}
# Write TS dt to CSV
write.table(dts, file = paste("/Users/myong/Documents/anon_publicd_timeseries.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
write.table(dt, file = paste("/Users/myong/Documents/anon_publicd_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# CleanEHR AIDA use case
# This script takes the available data and exports it for further analysis in Python
# Giovanni Colavizza <gcolavizza@turing.ac.uk> and Camila Rangel Smith <crangelsmith@turing.ac.uk>
# November 2018
# point this to the CleanEHR data
mean_tail_diff <- function(vector) {
diff <- mean(vector,na.rm=TRUE) - tail(vector,n=1)
return (diff)
}
data_folder = "datasets/data"
results_folder = "results"
library(purrr)
library(cleanEHR)
# full dataset
load(paste(data_folder,"anon_public_d.RData",sep="/"))
# use a smaller sample
#load(paste(data_folder,"sample_ccd",sep="/"))
# Extract all non-longitudinal data (demographic, time, survival status, diagnosis)
#dt <- ccd_demographic_table(ccd, dtype=TRUE)
dt <- ccd_demographic_table(ccd, dtype=TRUE)
# play a bit with the data
# explore spells
#head(ccd_unique_spell(anon_ccd, duration=2)[, c("episode_id", "spell")])
# how to get short variable names
#code2stname("NIHR_HIC_ICU_0553")[[1]]
# plot some longitudinal data
pdf(paste(results_folder,"example_episode.pdf",sep="/"))
plot_episode(ccd@episodes[[7]], c("h_rate",  "bilirubin", "fluid_balance_d", "temperature_central"))
dev.off()
# sex
pdf(paste(results_folder,"hist_sex.pdf",sep="/"))
barplot(prop.table(table(dt$SEX)))
dev.off()
# weight
pdf(paste(results_folder,"hist_weight.pdf",sep="/"))
hist(dt$WKG)
dev.off()
# height
pdf(paste(results_folder,"hist_height.pdf",sep="/"))
hist(dt$HCM)
dev.off()
# exporting the data to a python friendly format
# we want a tabular dataset with the time series reduced to a set of point statistics for simplicity (this could/should be improved upon eventually)
# Write demographics dt to CSV
write.table(dt, file = paste(data_folder,"anon_public_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
# get the codes of time series variables
names_ts_variables <- c()
counter <- 1
for (i in 1:length(ccd@episodes)){
for (n in names(ccd@episodes[[i]]@data)){
if (length(ccd@episodes[[i]]@data[n][[1]]) == 2){ # guarantee time series
names_ts_variables[[counter]] <- n
counter <- counter+1
}
}
}
names_ts_variables <- sort(unique(names_ts_variables))
short_names_ts_variables <- lapply(names_ts_variables, FUN = code2stname)
# our index is NIHR_HIC_ICU_0005, corresponding to a unique (per episode/patient) admission number, or ADNO
index_variable <- "NIHR_HIC_ICU_0005"
# prepare lists of measurements from time series
ts_measures <- c("mean","std","last","mean_tail_diff")
#ts_measures <- c("mean","1st_quartile","median","3rd_quartile","std","max","min")
#ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(quantile,probs=c(0.25),na.rm=TRUE),partial(quantile,probs=c(0.5),na.rm=TRUE),partial(quantile,probs=c(0.75),na.rm=TRUE),partial(sd),partial(max, na.rm = TRUE),partial(min, na.rm = TRUE))
ts_measures_funcs <- c(partial(mean,na.rm=TRUE),partial(sd),partial(tail,n=1),partial(mean_tail_diff))
names_for_dts <- c("ADNO")
for (sn in short_names_ts_variables){
for (mes in ts_measures){
names_for_dts <- append(names_for_dts,paste(sn,mes,sep = "_"))
}
}
dts <- data.frame(matrix(NA, nrow=0, ncol=length(names_for_dts)))
names(dts) <- names_for_dts
## prepare TS dataset
for (i in 1:length(ccd@episodes)){
adno <- as.numeric(ccd@episodes[[i]]@data[index_variable][[1]])
measurements <- c(adno)
for (n in names_ts_variables){
# Add time limit of 48 hours to measure TS data!
dt_ <- ccd@episodes[[i]]@data[n][[1]]
time_ = dt_$time <10
dt_ <- dt_[time_,]
values <- dt_[time_,]["item2d"][[1]]
if (!is.null(dt_) && !is_empty(values)){
for (measure in ts_measures_funcs){
measurements <- c(measurements,measure(as.numeric(values))[[1]])
}
} else {
measurements <- c(measurements,rep(NA,length(ts_measures)))
}
}
dts <- rbind(dts,measurements)
names(dts) <- names_for_dts
}
# Write TS dt to CSV
write.table(dts, file = paste("/Users/myong/Documents/anon_publicd_timeseries.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
write.table(dt, file = paste("/Users/myong/Documents/anon_publicd_demographic.csv",sep="/"),row.names=FALSE, na="",col.names=TRUE, sep=",")
setwd("~/Documents/workspace/mlflow/examples/r_wine")
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
setwd("~/Documents/workspace/CROP/versioning/Data_model/test_model")
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
mlflow::mlflow_run(uri="arima", entry_point = "train.R")
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_get_tracking_uri()
mlflow_rfunc_serve(model_uri="mlruns/0/6170ff43a00f4a67a78ed491bf3b102a/artifacts/model", port=8090)
mlflow_rfunc_serve(model_uri="mlruns/0/6170ff43a00f4a67a78ed491bf3b102a/artifacts/model", port=8090)
mlflow_rfunc_serve(model_uri="mlruns/0/6170ff43a00f4a67a78ed491bf3b102a/artifacts/model", port=8090)
forecast = forecaster(model, split.Data$tsel$Lights[split.Data$testSelIndex], 48)
forecast
forecaster = crate (function (input, hour) {
forecast::forecast(model, xreg=input, h = hour)
})
forecast = forecaster(split.Data$tsel$Lights[split.Data$testSelIndex], 48)
forecast = forecaster(split.Data$tsel$Lights[split.Data$testSelIndex], 48)
forecaster = crate (function (input, hour) {
forecast::forecast(model, xreg=input, h = hour)
})
forecast = forecaster(split.Data$tsel$Lights[split.Data$testSelIndex], 48)
with(mlflow_start_run(), {
#model = trainArima(available.Data=split.Data$tsel, trainIndex = split.Data$trainSelIndex)
#forecaster = crate (function (input, hour) {
#  forecast::forecast(model, xreg=input, h = hour)
#})
#forecast = forecaster(split.Data$tsel$Lights[split.Data$testSelIndex], 48)
forecaster = crate(function (available.Data, trainIndex, forecastIndex) {
p = 4 # AR order
d = 1 # degree of difference
q = 2 # MA order
MINIMIZE_CONDITIONAL_SUM_OF_SQUARES = "CSS"
model = forecast::Arima(available.Data$Sensor_temp[trainIndex], xreg =  available.Data$Lights[trainIndex],
order = c(p,d,q),
seasonal = list(order=c(1,1,0),period=24),method = MINIMIZE_CONDITIONAL_SUM_OF_SQUARES)
results = forecast::forecast(model,xreg = available.Data$Lights[forecastIndex], h=48)
list(upper=results$upper, lower=results$lower, mean=results$mean)
})
forecast = forecaster(split.Data$tsel, split.Data$trainSelIndex, split.Data$testSelIndex)
message("ARIMA (timestamp)=", forecastDataStart)
message("TestParam=", mlflow_param("testInput", "NA", "string"))
mlflow_log_param("Historical Data", historicalDataStart)
mlflow_log_param("Historical Days", daysOfHistoryForTraining)
mlflow_log_param("Forecast Starts", forecastDataStart)
mlflow_log_metric("RMSE", 2)
mlflow_log_model(forecaster, "model")
})
forecast
mlflow_rfunc_serve(model_uri="mlruns/0/2fe7a54452b54c66a6611ba2ca76143d/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/23e8d3aca3684b06ac0c91d63532718e/eartifacts/model", port=8090)
.Last.error.trace
mlflow_rfunc_serve(model_uri="mlruns/0/23e8d3aca3684b06ac0c91d63532718e/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/7fd6b22e1c3844229f2eb5a773179f4c/artifacts/model", port=8090)
forecaster = crate(function (available.Data, trainIndex, forecastIndex) {
p = 4 # AR order
d = 1 # degree of difference
q = 2 # MA order
MINIMIZE_CONDITIONAL_SUM_OF_SQUARES = "CSS"
model = forecast::Arima(available.Data$Sensor_temp[trainIndex], xreg =  available.Data$Lights[trainIndex],
order = c(p,d,q),
seasonal = list(order=c(1,1,0),period=24),method = MINIMIZE_CONDITIONAL_SUM_OF_SQUARES)
results = forecast::predict(model,xreg = available.Data$Lights[forecastIndex], h=48)
list(upper=results$upper, lower=results$lower, mean=results$mean)
})
forecast = forecaster(split.Data$tsel, split.Data$trainSelIndex, split.Data$testSelIndex)
model
model$x
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/c25fecd5171348b0883d6cae961f7703/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/0c28511bc24e43e99f2d2c467e0433f6/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/5565b535721d41509cb6fa09a843458a/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
mlflow_rfunc_serve(model_uri="mlruns/0/a138aa6e593542f98965bc8b71da1e3f/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(testInput="Hello May"))
setwd("~/Documents/workspace/mlflow/examples/r_wine")
mlflow::mlflow_run(uri="r_wine", entry_point = "train.R", parameters = list(alpha=0.2))
setwd("~/Documents/workspace/mlflow/examples")
mlflow::mlflow_run(uri="r_wine", entry_point = "train.R", parameters = list(alpha=0.2))
mlflow_rfunc_serve(model_uri="mlruns/0/537efedd6e1e473980d7efc24b184066/artifacts/model", port=8090)
getwd
getwd()
setwd("~/Documents/workspace/mlflow/examples/r_wine")
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
.x
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
source('~/Documents/workspace/mlflow/examples/r_wine/train.R')
setwd("~/Documents/workspace/CROP/versioning/Data_model/test_model")
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
forecast
mlflow_rfunc_serve(model_uri="mlruns/0/c32a221270734c55b43ba3de79f17b34/artifacts/model", port=8090)
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
.Last.error.trace
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
forecaster()
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
forecaster()
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
mlflow::mlflow_run(uri="arima", entry_point = "train.R", parameters = list(horizon=2))
.Last.error.trace
source('~/Documents/workspace/CROP/versioning/Data_model/test_model/arima/train.R')
